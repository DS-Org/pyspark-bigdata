{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative recommendation using Alternative least sqaures - ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS,Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ALS-Movie-recommendations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rdd\n",
    "movies_rdd = spark.sparkContext.textFile(\"./datasets/ml-100k/u.data\")\n",
    "sc.setCheckpointDir('checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint vs cache\n",
    "\n",
    "[https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/6-CacheAndCheckpoint.md](https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/6-CacheAndCheckpoint.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating is a data structure provided by ALS, this contains the data on which the recommedation to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating data structure accepts userid:int, product:int, rating:float\n",
    "movies_ratings = movies_rdd.map(lambda x : x.split()).map(lambda field : \n",
    "                                                      Rating(int(field[0]), int(field[1]) , float(field[2])) ).cache()\n",
    "# as movies ratings will be evaluated many times inside ALS method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training recommedation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to more about the rank and other parameters please \n",
    "\n",
    "* [ALS](https://stackoverflow.com/a/45838873)\n",
    "\n",
    "* [Rank](https://stackoverflow.com/a/30732231)\n",
    "\n",
    "\n",
    "Signature: ALS.train(ratings, rank, iterations=5, lambda_=0.01, blocks=-1, nonnegative=False, seed=None)\n",
    "\n",
    "Docstring:\n",
    "Train a matrix factorization model given an RDD of ratings by users\n",
    "for a subset of products. The ratings matrix is approximated as the\n",
    "product of two lower-rank matrices of a given rank (number of\n",
    "features). To solve for these features, ALS is run iteratively with\n",
    "a configurable level of parallelism.\n",
    "\n",
    ":param ratings:\n",
    "  RDD of `Rating` or (userID, productID, rating) tuple.\n",
    ":param rank:\n",
    "  Number of features to use (also referred to as the number of latent factors).\n",
    ":param iterations:\n",
    "  Number of iterations of ALS.\n",
    "  (default: 5)\n",
    ":param lambda_:\n",
    "  Regularization parameter.\n",
    "  (default: 0.01)\n",
    ":param blocks:\n",
    "  Number of blocks used to parallelize the computation. A value\n",
    "  of -1 will use an auto-configured number of blocks.\n",
    "  (default: -1)\n",
    ":param nonnegative:\n",
    "  A value of True will solve least-squares with nonnegativity\n",
    "  constraints.\n",
    "  (default: False)\n",
    ":param seed:\n",
    "  Random seed for initial matrix factorization model. A value\n",
    "  of None will use system time as the seed.\n",
    "  (default: None)\n",
    "\n",
    ".. versionadded:: 0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 20\n",
    "numIterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ALS.train(ratings=movies_ratings,rank=rank,iterations=numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=50, rating=5.023538948659228),\n",
       " Rating(user=0, product=172, rating=4.954395508936481),\n",
       " Rating(user=0, product=181, rating=4.697438278245935),\n",
       " Rating(user=0, product=630, rating=4.6269015067165435),\n",
       " Rating(user=0, product=174, rating=4.590881185280563),\n",
       " Rating(user=0, product=173, rating=4.510254117272762),\n",
       " Rating(user=0, product=195, rating=4.356694170662087),\n",
       " Rating(user=0, product=184, rating=4.284870788289972),\n",
       " Rating(user=0, product=109, rating=4.2698675552721514),\n",
       " Rating(user=0, product=686, rating=4.139831430935725)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid = 0\n",
    "numberOfRecommendations=10\n",
    "recommendations = model.recommendProducts(userid,numberOfRecommendations)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load movie names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names= spark.sparkContext.textFile(\"./datasets/ml-100k/u.item\")\n",
    "movie_names=movie_names.map(lambda x : (int(x.split(\"|\")[0]), x.split(\"|\")[1]))\n",
    "movie_name_dict=movie_names.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rated_movies = movies_ratings.filter(lambda x : x[0] == userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Star Wars (1977)  - score: 5.0\n",
      "Movie: Empire Strikes Back, The (1980)  - score: 5.0\n",
      "Movie: Gone with the Wind (1939)  - score: 1.0\n"
     ]
    }
   ],
   "source": [
    "for user_rated_movie in user_rated_movies.collect():\n",
    "    print(\"Movie: %s  - score: %.1f\" % (movie_name_dict[user_rated_movie[1]] , user_rated_movie[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: Star Wars (1977)  - score: 5.0235389487\n",
      "Movie: Empire Strikes Back, The (1980)  - score: 4.9543955089\n",
      "Movie: Return of the Jedi (1983)  - score: 4.6974382782\n",
      "Movie: Great Race, The (1965)  - score: 4.6269015067\n",
      "Movie: Raiders of the Lost Ark (1981)  - score: 4.5908811853\n",
      "Movie: Princess Bride, The (1987)  - score: 4.5102541173\n",
      "Movie: Terminator, The (1984)  - score: 4.3566941707\n",
      "Movie: Army of Darkness (1993)  - score: 4.2848707883\n",
      "Movie: Mystery Science Theater 3000: The Movie (1996)  - score: 4.2698675553\n",
      "Movie: Perfect World, A (1993)  - score: 4.1398314309\n"
     ]
    }
   ],
   "source": [
    "for recommendation in recommendations:\n",
    "    print(\"Movie: %s  - score: %.10f\" % (movie_name_dict[recommendation[1]] , recommendation[2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations not so promising this could be due to many reasons\n",
    "\n",
    "![](./images/ALS.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
